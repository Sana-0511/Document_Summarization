{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sana-0511/Document_Summarization-/blob/main/TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpGbtgMmk-7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6247a06-b704-4d43-b10c-b32d39739164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import nltk  # Natural Language Toolkit for NLP tasks\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDF vectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity  # Cosine similarity metric\n",
        "\n",
        "# Download the punkt tokenizer for sentence tokenization\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required utility\n",
        "!apt-get install wget\n",
        "\n",
        "# Import the necessary libraries\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Provide the Google Drive link\n",
        "google_drive_link = 'https://drive.google.com/uc?id=1FV5aYhpvl6NFrH7aYzEVg8pmO_yokYoI'\n",
        "\n",
        "# Specify the output file name\n",
        "zip_file = 'example.zip'\n",
        "\n",
        "# Download the zip file\n",
        "!wget --no-check-certificate $google_drive_link -O $zip_file\n",
        "\n",
        "# Create a directory to extract the contents\n",
        "extracted_dir = 'extracted_content'\n",
        "os.makedirs(extracted_dir, exist_ok=True)\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n",
        "# List the files in the extracted directory\n",
        "extracted_files = os.listdir(extracted_dir)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY8Y27NSgUHj",
        "outputId": "bbed136a-b235-45d3-99ee-1f426cf73e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "--2024-01-13 11:25:02--  https://drive.google.com/uc?id=1FV5aYhpvl6NFrH7aYzEVg8pmO_yokYoI\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.126.102, 74.125.126.100, 74.125.126.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.126.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1FV5aYhpvl6NFrH7aYzEVg8pmO_yokYoI [following]\n",
            "--2024-01-13 11:25:02--  https://drive.usercontent.google.com/download?id=1FV5aYhpvl6NFrH7aYzEVg8pmO_yokYoI\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.136.132, 2607:f8b0:4001:c34::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.136.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2572 (2.5K) [application/octet-stream]\n",
            "Saving to: ‘example.zip’\n",
            "\n",
            "example.zip         100%[===================>]   2.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-13 11:25:04 (213 MB/s) - ‘example.zip’ saved [2572/2572]\n",
            "\n",
            "Files extracted: ['example']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(file_path):\n",
        "    # Function to read the content of a file\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text"
      ],
      "metadata": {
        "id": "2sD3cvzglgME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_extraction(text, num_sentences=5):\n",
        "    # Tokenize the text into sentences using the punkt tokenizer\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "    # Create TF-IDF vectorizer\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # Fit and transform the sentences using TF-IDF to obtain a numerical representation\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
        "\n",
        "    # Calculate cosine similarity between sentences to measure their similarity\n",
        "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    # Identify the most important sentences based on their similarity scores\n",
        "    sentence_scores = [(i, sum(similarity_matrix[i])) for i in range(len(sentences))]\n",
        "    sentence_scores = sorted(sentence_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Select the top N sentences for the summary\n",
        "    summary_sentences = [sentences[i] for i, _ in sentence_scores[:num_sentences]]\n",
        "\n",
        "    return ' '.join(summary_sentences)"
      ],
      "metadata": {
        "id": "dTxVzjDPljFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Specify the path to your text file\n",
        "    file_path = '/content/extracted_content/example/msft.txt'\n",
        "\n",
        "    # Read the file content\n",
        "    text_content = read_file(file_path)\n",
        "\n",
        "    # Set the number of sentences you want in the summary\n",
        "    num_summary_sentences = 3\n",
        "\n",
        "    # Generate the summary using TF-IDF sentence extraction\n",
        "    summary = sentence_extraction(text_content, num_summary_sentences)\n",
        "\n",
        "    # Print the generated summary\n",
        "    print(\"\\nSummary:\\n\", summary)\n"
      ],
      "metadata": {
        "id": "FAinEMKfmCPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec01786-4978-4007-a0eb-1f1016fbfac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            " As part of the program, the Redmond giant which wants to expand its reach and is planning to build a strong developer ecosystem in India with the program will set up the core AI infrastructure and IoT Hub for the selected campuses. The company will provide AI development tools and Azure AI services such as Microsoft Cognitive Services, Bot Services and Azure Machine Learning.According to Manish Prakash, Country General Manager-PS, Health and Education, Microsoft India, said, \"With AI being the defining technology of our time, it is transforming lives and industry and the jobs of tomorrow will require a different skillset. In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub which has been launched to empower the next generation of students with AI-ready skills.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub which has been launched to empower the next generation of students with AI-ready skills\n",
        "Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100 institutions with AI infrastructure, course content and curriculum, developer support, development tools and give students access to cloud and AI services\n",
        "As part of the program, the Redmond giant which wants to expand its reach and is planning to build a strong developer ecosystem in India with the program will set up the core AI infrastructure and IoT Hub for the selected campuses\n",
        "The company will provide AI development tools and Azure AI services such as Microsoft Cognitive Services, Bot Services and Azure Machine Learning.According to Manish Prakash, Country General Manager-PS, Health and Education, Microsoft India, said, \"With AI being the defining technology of our time, it is transforming lives and industry and the jobs of tomorrow will require a different skillset\n",
        "This will require more collaborations and training and working with AI\n",
        "That’s why it has become more critical than ever for educational institutions to integrate new cloud and AI technologies\n",
        "The program is an attempt to ramp up the institutional set-up and build capabilities among the educators to educate the workforce of tomorrow.\" The program aims to build up the cognitive skills and in-depth understanding of developing intelligent cloud connected solutions for applications across industry\n",
        "Earlier in April this year, the company announced Microsoft Professional Program In AI as a learning track open to the public\n",
        "The program was developed to provide job ready skills to programmers who wanted to hone their skills in AI and data science with a series of online courses which featured hands-on labs and expert instructors as well\n",
        "This program also included developer-focused AI school that provided a bunch of assets to help build AI skills.\n",
        "\n",
        "Summary: As part of the program, the Redmond giant which wants to expand its reach and is planning to build a strong developer ecosystem in India with the program will set up the core AI infrastructure and IoT Hub for the selected campuses. The company will provide AI development tools and Azure AI services such as Microsoft Cognitive Services, Bot Services and Azure Machine Learning.According to Manish Prakash, Country General Manager-PS, Health and Education, Microsoft India, said, \"With AI being the defining technology of our time, it is transforming lives and industry and the jobs of tomorrow will require a different skillset. In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub which has been launched to empower the next generation of students with AI-ready skills."
      ],
      "metadata": {
        "id": "aWm45BlONQo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge\n",
        "\n",
        "# Your original text and generated summary\n",
        "original_text = text_content\n",
        "generated_summary = summary\n",
        "\n",
        "# Initialize the Rouge object\n",
        "rouge = Rouge()\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "scores = rouge.get_scores(generated_summary, original_text)\n",
        "\n",
        "# Print the scores\n",
        "print(\"ROUGE Scores:\")\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNtKD77akR9f",
        "outputId": "0cecbcfb-a6df-47b9-9339-c45a54624978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n",
            "ROUGE Scores:\n",
            "[{'rouge-1': {'r': 0.5138121546961326, 'p': 1.0, 'f': 0.6788321123040654}, 'rouge-2': {'r': 0.42517006802721086, 'p': 0.9920634920634921, 'f': 0.5952380910380953}, 'rouge-l': {'r': 0.5138121546961326, 'p': 1.0, 'f': 0.6788321123040654}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROUGE-1:\n",
        "\n",
        "Precision (p): 1.000\n",
        "Recall (r): 0.514\n",
        "F1-score (f): 0.679\n",
        "\n",
        "ROUGE-2:\n",
        "\n",
        "Precision (p): 0.992\n",
        "Recall (r): 0.425\n",
        "F1-score (f): 0.595\n",
        "\n",
        "ROUGE-L:\n",
        "\n",
        "Precision (p): 1.000\n",
        "Recall (r): 0.514\n",
        "F1-score (f): 0.679\n",
        "\n",
        "These scores suggest very high precision in terms of matching unigrams (ROUGE-1) and capturing the longest common subsequence (ROUGE-L). The recall values are also relatively high, indicating that the generated summary effectively covers a significant portion of the important content from the original text. The F1-score, balancing precision and recall, reflects a strong overall performance, suggesting that the generated summary is both accurate and comprehensive."
      ],
      "metadata": {
        "id": "-cegh8LmLOoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Specify the path to your text file\n",
        "    file_path = '/content/extracted_content/example/computer.txt'\n",
        "\n",
        "    # Read the file content\n",
        "    text_content = read_file(file_path)\n",
        "\n",
        "    # Set the number of sentences you want in the summary\n",
        "    num_summary_sentences = 3\n",
        "\n",
        "    # Generate the summary using TF-IDF sentence extraction\n",
        "    summary = sentence_extraction(text_content, num_summary_sentences)\n",
        "\n",
        "    # Print the generated summary\n",
        "    print(\"\\nSummary:\\n\", summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlxABe8UgYZu",
        "outputId": "3d41226a-7be1-4633-9b4d-4b75b047eaba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            " This term may also refer to a group of computers that are linked and function together, such as a computer network or computer cluster. Modern digital electronic computers can perform generic sets of operations known as programs. A broad range of industrial and consumer products use computers as control systems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A computer is a machine that can be programmed to carry out sequences of arithmetic or logical operations automatically. Modern digital electronic computers can perform generic sets of operations known as programs. These programs enable computers to perform a wide range of tasks. A computer system is a nominally complete computer that includes the hardware, operating system, and peripheral equipment needed and used for full operation. This term may also refer to a group of computers that are linked and function together, such as a computer network or computer cluster. A broad range of industrial and consumer products use computers as control systems. Simple special-purpose devices like microwave ovens and remote controls are included, as are factory devices like industrial robots and computer-aided design, as well as general-purpose devices like personal computers and mobile devices like smartphones. Computers power the Internet, which links billions of other computers and users.\n",
        "\n",
        "Summary:\n",
        " This term may also refer to a group of computers that are linked and function together, such as a computer network or computer cluster. Modern digital electronic computers can perform generic sets of operations known as programs. A broad range of industrial and consumer products use computers as control systems."
      ],
      "metadata": {
        "id": "QTuXcmvMg-wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "# Your original text and generated summary\n",
        "original_text = text_content\n",
        "generated_summary = summary\n",
        "\n",
        "# Initialize the Rouge object\n",
        "rouge = Rouge()\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "scores = rouge.get_scores(generated_summary, original_text)\n",
        "\n",
        "# Print the scores\n",
        "print(\"ROUGE Scores:\")\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXEjVARUkQ9Q",
        "outputId": "7614d798-47bf-445d-b829-d05516d16d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "ROUGE Scores:\n",
            "[{'rouge-1': {'r': 0.4270833333333333, 'p': 1.0, 'f': 0.5985401417912516}, 'rouge-2': {'r': 0.3333333333333333, 'p': 0.9591836734693877, 'f': 0.4947368382775624}, 'rouge-l': {'r': 0.4270833333333333, 'p': 1.0, 'f': 0.5985401417912516}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROUGE-1:\n",
        "\n",
        "Precision (p): 1.000\n",
        "Recall (r): 0.427\n",
        "F1-score (f): 0.599\n",
        "\n",
        "ROUGE-2:\n",
        "\n",
        "Precision (p): 0.959\n",
        "Recall (r): 0.333\n",
        "F1-score (f): 0.495\n",
        "\n",
        "ROUGE-L:\n",
        "\n",
        "Precision (p): 1.000\n",
        "Recall (r): 0.427\n",
        "F1-score (f): 0.599\n",
        "\n",
        "These scores suggest high precision in terms of matching unigrams (ROUGE-1) and capturing the longest common subsequence (ROUGE-L). However, the recall values are moderate, indicating that while the generated summary contains correct unigrams and overlaps well with the reference in terms of the longest common subsequence, there may be some content from the original text that is not covered. The F1-score provides a balance between precision and recall, reflecting a good overall performance."
      ],
      "metadata": {
        "id": "1aNM2F5sLGtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Specify the path to your text file\n",
        "    file_path = '/content/extracted_content/example/space.txt'\n",
        "\n",
        "    # Read the file content\n",
        "    text_content = read_file(file_path)\n",
        "\n",
        "    # Set the number of sentences you want in the summary\n",
        "    num_summary_sentences = 3\n",
        "\n",
        "    # Generate the summary using TF-IDF sentence extraction\n",
        "    summary = sentence_extraction(text_content, num_summary_sentences)\n",
        "\n",
        "    # Print the generated summary\n",
        "    print(\"\\nSummary:\\n\", summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDtFurK7gYju",
        "outputId": "511d8d0f-eb49-46d2-8887-6b6334a8b78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            " But this is deeply controversial, because Einstein’s theory predicts the existence of a so-called singularity at the centre of black holes – a state of infinite gravity which would prevent anything from passing through to the white hole on the other side. But unlike black holes, there’s no consensus about whether white holes exist, or how they’d be formed.They are predicted by Einstein’s theory of gravity, and are most often mentioned in the context of ‘wormholes’, in which a black hole acts as the entry point to a tunnel through space and time, ending in a white hole somewhere else in the Universe. But then, quantum effects occurring around the surface of the black hole halt further collapse to a singularity, and instead begin to gradually turn the black hole into a white hole that’s spewing out the original star matter again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A white hole is a bizarre cosmic object which is intensely bright, and from which matter gushes rather than disappears. In other words, it’s the exact opposite of a black hole. But unlike black holes, there’s no consensus about whether white holes exist, or how they’d be formed.They are predicted by Einstein’s theory of gravity, and are most often mentioned in the context of ‘wormholes’, in which a black hole acts as the entry point to a tunnel through space and time, ending in a white hole somewhere else in the Universe. But this is deeply controversial, because Einstein’s theory predicts the existence of a so-called singularity at the centre of black holes – a state of infinite gravity which would prevent anything from passing through to the white hole on the other side. The process starts when an old massive star collapses under its own weight and forms a black hole. But then, quantum effects occurring around the surface of the black hole halt further collapse to a singularity, and instead begin to gradually turn the black hole into a white hole that’s spewing out the original star matter again. The process is mind-bendingly slow, though, so we may be in for a very long wait to find out if white holes really exist.\n",
        "\n",
        "Summary:\n",
        " But this is deeply controversial, because Einstein’s theory predicts the existence of a so-called singularity at the centre of black holes – a state of infinite gravity which would prevent anything from passing through to the white hole on the other side. But unlike black holes, there’s no consensus about whether white holes exist, or how they’d be formed.They are predicted by Einstein’s theory of gravity, and are most often mentioned in the context of ‘wormholes’, in which a black hole acts as the entry point to a tunnel through space and time, ending in a white hole somewhere else in the Universe. But then, quantum effects occurring around the surface of the black hole halt further collapse to a singularity, and instead begin to gradually turn the black hole into a white hole that’s spewing out the original star matter again."
      ],
      "metadata": {
        "id": "IuhSJ4hcgvlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge\n",
        "\n",
        "# Your original text and generated summary\n",
        "original_text = text_content\n",
        "generated_summary = summary\n",
        "\n",
        "# Initialize the Rouge object\n",
        "rouge = Rouge()\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "scores = rouge.get_scores(generated_summary, original_text)\n",
        "\n",
        "# Print the scores\n",
        "print(\"ROUGE Scores:\")\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFk4o4mPkN_N",
        "outputId": "639efeff-96ea-4bde-b3ff-81514c55c019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "ROUGE Scores:\n",
            "[{'rouge-1': {'r': 0.6911764705882353, 'p': 1.0, 'f': 0.8173912995145558}, 'rouge-2': {'r': 0.6700507614213198, 'p': 0.9924812030075187, 'f': 0.7999999951880625}, 'rouge-l': {'r': 0.6911764705882353, 'p': 1.0, 'f': 0.8173912995145558}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROUGE-1:\n",
        "\n",
        "Precision (p): 1.000\n",
        "Recall (r): 0.691\n",
        "F1-score (f): 0.817\n",
        "\n",
        "ROUGE-2:\n",
        "\n",
        "Precision (p): 0.992\n",
        "Recall (r): 0.670\n",
        "F1-score (f): 0.800\n",
        "\n",
        "ROUGE-L:\n",
        "\n",
        "Precision (p): 1.000\n",
        "Recall (r): 0.691\n",
        "F1-score (f): 0.817\n",
        "\n",
        "These scores indicate extremely high precision in terms of matching unigrams (ROUGE-1) and capturing the longest common subsequence (ROUGE-L). The recall values are also very high, suggesting that the generated summary effectively covers a substantial portion of the important content from the original text. The F1-score, balancing precision and recall, reflects an outstanding overall performance, indicating that the generated summary is both highly accurate and comprehensive."
      ],
      "metadata": {
        "id": "GybKBTH5LWcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REFERENCES\n",
        "\n",
        "https://www.geeksforgeeks.org/understanding-tf-idf-term-frequency-inverse-document-frequency/\n",
        "\n",
        "https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089\n",
        "\n",
        "https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3"
      ],
      "metadata": {
        "id": "bESkE4Y_dJTs"
      }
    }
  ]
}